{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75191928",
   "metadata": {},
   "source": [
    "# 📊 Clasificación de Ingresos con Spark ML - Google Colab\n",
    "\n",
    "## 🎯 **DataPros - Predicción de Ingresos >50K**\n",
    "\n",
    "**Objetivo:** Construir un modelo de clasificación binaria con Spark ML utilizando Logistic Regression para predecir si una persona gana más de 50K al año o no.\n",
    "\n",
    "**Dataset:** adult_income_sample.csv con 2000 registros simulados (cargado desde Google Drive)\n",
    "\n",
    "**Características:**\n",
    "- `age`: Edad de la persona (años)\n",
    "- `sex`: Género (Male, Female) \n",
    "- `workclass`: Tipo de empleo (Private, Self-emp, Gov)\n",
    "- `fnlwgt`: Peso estadístico asociado al registro\n",
    "- `education`: Nivel educativo (Bachelors, HS-grad, 11th, Masters, etc.)\n",
    "- `hours_per_week`: Horas trabajadas por semana\n",
    "- `label`: Clase objetivo (>50K o <=50K)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ **INSTRUCCIONES IMPORTANTES:**\n",
    "\n",
    "### 📂 **Antes de ejecutar este notebook:**\n",
    "\n",
    "1. **Sube el archivo `adult_income_sample.csv` a tu Google Drive**\n",
    "2. **Ejecuta la primera celda para montar Google Drive**\n",
    "3. **Verifica que el archivo esté en la ruta correcta**\n",
    "4. **Ejecuta todas las celdas secuencialmente**\n",
    "\n",
    "### 🔗 **Ventajas de usar Google Drive:**\n",
    "- ✅ **Control de versiones**: Mantienes el dataset original\n",
    "- ✅ **Compatibilidad**: Mismo CSV funciona en VS Code y Colab\n",
    "- ✅ **Reproducibilidad**: Resultados consistentes entre entornos\n",
    "- ✅ **Colaboración**: Fácil compartir datos con el equipo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b9111",
   "metadata": {},
   "source": [
    "## 🔧 **1. Configuración del Entorno Google Colab**\n",
    "\n",
    "Instalamos PySpark y montamos Google Drive para acceder al dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar PySpark en Google Colab\n",
    "!pip install pyspark\n",
    "\n",
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"✅ PySpark instalado y Google Drive montado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "import os\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb318bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear sesión de Spark optimizada para Google Colab\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IncomeClassification_Colab\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"false\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"false\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar nivel de log para reducir salida\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"✅ Sesión Spark iniciada en Google Colab\")\n",
    "print(f\"🔢 Versión de Spark: {spark.version}\")\n",
    "print(f\"📱 Aplicación: {spark.sparkContext.appName}\")\n",
    "print(f\"🖥️  Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d56a9",
   "metadata": {},
   "source": [
    "## 📂 **2. Carga y Exploración de Datos desde Google Drive**\n",
    "\n",
    "Cargamos el archivo CSV desde Google Drive y exploramos la estructura de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que el archivo existe en Google Drive\n",
    "file_path = \"/content/drive/MyDrive/adult_income_sample.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"✅ Archivo encontrado: {file_path}\")\n",
    "    print(f\"📁 Tamaño del archivo: {os.path.getsize(file_path)} bytes\")\n",
    "else:\n",
    "    print(\"❌ ARCHIVO NO ENCONTRADO!\")\n",
    "    print(\"🔍 Archivos disponibles en Google Drive:\")\n",
    "    !ls \"/content/drive/MyDrive/\" | head -10\n",
    "    print(\"\\n⚠️  Por favor, sube 'adult_income_sample.csv' a tu Google Drive\")\n",
    "    print(\"💡 O ajusta la ruta en la variable 'file_path'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde Google Drive\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "print(f\"✅ Datos cargados desde Google Drive: {df.count()} registros, {len(df.columns)} columnas\")\n",
    "print(\"\\n📊 Esquema del DataFrame:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar primeros 10 registros\n",
    "print(\"📋 Primeros 10 registros:\")\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32537dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de la distribución de la variable objetivo\n",
    "print(\"📈 Distribución de la variable objetivo (label):\")\n",
    "df.groupBy(\"label\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "print(\"\\n📊 Estadísticas descriptivas de variables numéricas:\")\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206199de",
   "metadata": {},
   "source": [
    "## 🔄 **3. Preprocesamiento de Variables Categóricas**\n",
    "\n",
    "Aplicamos StringIndexer y OneHotEncoder para transformar las variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variables categóricas\n",
    "categorical_cols = ['sex', 'workclass', 'education']\n",
    "\n",
    "print(\"🔄 Aplicando StringIndexer a variables categóricas...\")\n",
    "\n",
    "# StringIndexer para variables categóricas\n",
    "indexers = []\n",
    "for col_name in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_index\")\n",
    "    indexers.append(indexer)\n",
    "    print(f\"  ✓ StringIndexer creado para: {col_name}\")\n",
    "\n",
    "# StringIndexer para la variable objetivo (label)\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "indexers.append(label_indexer)\n",
    "print(f\"  ✓ StringIndexer creado para: label\")\n",
    "\n",
    "print(f\"\\n📝 Total de StringIndexers: {len(indexers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder para variables categóricas (no para la etiqueta)\n",
    "print(\"🔄 Aplicando OneHotEncoder a variables categóricas...\")\n",
    "\n",
    "encoders = []\n",
    "for col_name in categorical_cols:\n",
    "    encoder = OneHotEncoder(inputCol=f\"{col_name}_index\", outputCol=f\"{col_name}_encoded\")\n",
    "    encoders.append(encoder)\n",
    "    print(f\"  ✓ OneHotEncoder creado para: {col_name}\")\n",
    "\n",
    "print(f\"\\n Total de OneHotEncoders: {len(encoders)}\")\n",
    "print(\" Preprocesamiento de variables categóricas configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72b69",
   "metadata": {},
   "source": [
    "## 🔧 **4. Ensamblaje de Características**\n",
    "\n",
    "Combinamos todas las características en un vector único usando VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características para el vector final\n",
    "numeric_cols = ['age', 'fnlwgt', 'hours_per_week']\n",
    "categorical_encoded_cols = ['sex_encoded', 'workclass_encoded', 'education_encoded']\n",
    "\n",
    "# Combinar todas las características\n",
    "feature_cols = numeric_cols + categorical_encoded_cols\n",
    "\n",
    "print(\" Configurando VectorAssembler...\")\n",
    "print(f\" Características numéricas: {numeric_cols}\")\n",
    "print(f\" Características categóricas codificadas: {categorical_encoded_cols}\")\n",
    "print(f\" Total de características: {len(feature_cols)}\")\n",
    "\n",
    "# Crear VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "print(\" VectorAssembler configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc493698",
   "metadata": {},
   "source": [
    "##  **5. Definición y Entrenamiento del Modelo**\n",
    "\n",
    "Configuramos el modelo de Logistic Regression y creamos el Pipeline completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295280a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar modelo de Logistic Regression\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label_index\",\n",
    "    predictionCol=\"prediction\",\n",
    "    probabilityCol=\"probability\",\n",
    "    maxIter=100,\n",
    "    regParam=0.01\n",
    ")\n",
    "\n",
    "print(\"Modelo configurado:\")\n",
    "print(f\"   Tipo: Logistic Regression\")\n",
    "print(f\"   Máximo iteraciones: {lr.getMaxIter()}\")\n",
    "print(f\"   Parámetro regularización: {lr.getRegParam()}\")\n",
    "print(\" Modelo de Logistic Regression configurado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear Pipeline con todas las etapas\n",
    "stages = indexers + encoders + [assembler, lr]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "print(\"🔧 Pipeline creado con las siguientes etapas:\")\n",
    "for i, stage in enumerate(stages):\n",
    "    print(f\"  {i+1:2d}. {type(stage).__name__}\")\n",
    "\n",
    "print(f\"\\n Total de etapas en el Pipeline: {len(stages)}\")\n",
    "print(\" Pipeline configurado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a573087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "print(\" Iniciando entrenamiento del modelo...\")\n",
    "model = pipeline.fit(df)\n",
    "print(\" Modelo entrenado exitosamente!\")\n",
    "\n",
    "# Obtener información del modelo entrenado\n",
    "lr_model = model.stages[-1]  # El último stage es el LogisticRegression\n",
    "print(f\"\\n Información del modelo entrenado:\")\n",
    "print(f\"   Número de iteraciones realizadas: {lr_model.summary.totalIterations}\")\n",
    "print(f\"   Objective History (últimos 5): {lr_model.summary.objectiveHistory[-5:]}\")\n",
    "print(\" Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fcbe2a",
   "metadata": {},
   "source": [
    "##  **6. Evaluación del Modelo**\n",
    "\n",
    "Evaluamos el modelo entrenado y analizamos las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones sobre el conjunto de entrenamiento\n",
    "predictions = model.transform(df)\n",
    "\n",
    "print(\" Predicciones generadas\")\n",
    "print(\" Mostrando las primeras 20 predicciones con todas las columnas relevantes:\")\n",
    "\n",
    "# Mostrar predicciones\n",
    "predictions.select(\"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\", \n",
    "                  \"label\", \"prediction\", \"probability\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e899e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con métricas\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label_index\", rawPredictionCol=\"rawPrediction\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\" Métricas de evaluación:\")\n",
    "print(f\"   Área bajo la curva ROC (AUC): {auc:.4f}\")\n",
    "\n",
    "# Calcular precisión (accuracy)\n",
    "correct_predictions = predictions.filter(col(\"label_index\") == col(\"prediction\")).count()\n",
    "total_predictions = predictions.count()\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"   Precisión (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"   Predicciones correctas: {correct_predictions}\")\n",
    "print(f\"   Total de predicciones: {total_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8537da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "print(\" Matriz de confusión:\")\n",
    "confusion_matrix = predictions.groupBy(\"label_index\", \"prediction\").count().orderBy(\"label_index\", \"prediction\")\n",
    "confusion_matrix.show()\n",
    "\n",
    "# Distribución de predicciones\n",
    "print(\"\\n Distribución de predicciones:\")\n",
    "predictions.groupBy(\"prediction\").count().orderBy(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e06b3",
   "metadata": {},
   "source": [
    "###  **Reflexión sobre los Resultados**\n",
    "\n",
    "**¿Qué observamos sobre los resultados?**\n",
    "\n",
    "1. **Distribución de probabilidades**: El modelo genera probabilidades entre 0 y 1 para cada predicción, siendo más confiable cuando las probabilidades están más cerca de 0 o 1.\n",
    "\n",
    "2. **Precisión del modelo**: La precisión (accuracy) nos indica qué porcentaje de predicciones fueron correctas.\n",
    "\n",
    "3. **AUC**: El área bajo la curva ROC nos da una medida de qué tan bien el modelo puede distinguir entre las dos clases.\n",
    "\n",
    "4. **Características importantes**: Variables como educación, edad y horas trabajadas probablemente tienen mayor peso en las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591cadd",
   "metadata": {},
   "source": [
    "##  **7. Predicción con Nuevos Datos**\n",
    "\n",
    "Creamos nuevos registros y aplicamos el modelo entrenado para hacer predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevos datos de prueba (9 registros como mínimo requerido)\n",
    "new_data = [\n",
    "    (35, \"Male\", \"Private\", 150000, \"Bachelors\", 45),      # Perfil promisorio: educación alta, horas normales\n",
    "    (25, \"Female\", \"Private\", 120000, \"HS-grad\", 35),      # Joven con educación básica\n",
    "    (45, \"Male\", \"Gov\", 200000, \"Masters\", 50),            # Gobierno, educación alta, experiencia\n",
    "    (22, \"Female\", \"Self-emp\", 80000, \"11th\", 20),         # Joven, trabajo independiente, educación baja\n",
    "    (55, \"Male\", \"Private\", 300000, \"Doctorate\", 60),      # Doctorado, muchas horas, experiencia\n",
    "    (30, \"Female\", \"Private\", 100000, \"Some-college\", 40), # Educación universitaria parcial\n",
    "    (28, \"Male\", \"Self-emp\", 90000, \"Bachelors\", 55),      # Independiente con título universitario\n",
    "    (40, \"Female\", \"Gov\", 180000, \"Masters\", 42),          # Gobierno con maestría\n",
    "    (33, \"Male\", \"Private\", 140000, \"Assoc-voc\", 38)       # Educación técnica/vocacional\n",
    "]\n",
    "\n",
    "columns = [\"age\", \"sex\", \"workclass\", \"fnlwgt\", \"education\", \"hours_per_week\"]\n",
    "new_df = spark.createDataFrame(new_data, columns)\n",
    "\n",
    "print(\" Nuevos datos creados para predicción:\")\n",
    "new_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el modelo entrenado a los nuevos datos\n",
    "print(\" Aplicando modelo entrenado a nuevos datos...\")\n",
    "new_predictions = model.transform(new_df)\n",
    "\n",
    "print(\"\\n📊 Resultados de predicciones para nuevos datos:\")\n",
    "new_predictions.select(\"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\", \n",
    "                      \"prediction\", \"probability\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6971f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretar las predicciones de manera más legible\n",
    "print(\"📋 Interpretación de las predicciones:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = new_predictions.select(\"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\", \"prediction\", \"probability\").collect()\n",
    "\n",
    "for i, row in enumerate(results, 1):\n",
    "    prediction_label = \">50K\" if row.prediction == 1.0 else \"<=50K\"\n",
    "    prob_high = row.probability[1]  # Probabilidad de clase >50K\n",
    "    prob_low = row.probability[0]   # Probabilidad de clase <=50K\n",
    "    \n",
    "    print(f\" Persona {i}:\")\n",
    "    print(f\"    Perfil: {row.age} años, {row.sex}, {row.workclass}, {row.education}, {row.hours_per_week}h/semana\")\n",
    "    print(f\"    Predicción: {prediction_label}\")\n",
    "    print(f\"    Probabilidad >50K: {prob_high:.3f} | Probabilidad <=50K: {prob_low:.3f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490f8a5",
   "metadata": {},
   "source": [
    "##  **Resumen Final del Proyecto**\n",
    "\n",
    "**¡Clasificación de Ingresos completada exitosamente para DataPros!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce46f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final del proyecto\n",
    "print(\"🎯 RESUMEN DEL PROYECTO - DATAPROS\")\n",
    "print(\"=\" * 60)\n",
    "print(\" Datos cargados desde Google Drive: 2000 registros\")\n",
    "print(\" Variables categóricas procesadas con StringIndexer y OneHotEncoder\")\n",
    "print(\" Características ensambladas con VectorAssembler\")\n",
    "print(\" Modelo de Logistic Regression entrenado con Pipeline\")\n",
    "print(\" Modelo evaluado con métricas de rendimiento\")\n",
    "print(\" Predicciones realizadas sobre 9 nuevos registros\")\n",
    "print(f\" Precisión del modelo: {accuracy:.1%}\")\n",
    "print(f\" AUC del modelo: {auc:.3f}\")\n",
    "print(\"\\n DataPros ahora puede predecir ingresos basado en características demográficas y laborales!\")\n",
    "print(\"\\n Ejecutado exitosamente en Google Colab con datos desde Google Drive\")\n",
    "\n",
    "# Cerrar sesión Spark\n",
    "spark.stop()\n",
    "print(\"\\n Sesión Spark cerrada correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbdacaa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  **Evidencia de Ejecución**\n",
    "\n",
    
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
