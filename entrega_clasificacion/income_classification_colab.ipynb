{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75191928",
   "metadata": {},
   "source": [
    "# ðŸ“Š ClasificaciÃ³n de Ingresos con Spark ML - Google Colab\n",
    "\n",
    "## ðŸŽ¯ **DataPros - PredicciÃ³n de Ingresos >50K**\n",
    "\n",
    "**Objetivo:** Construir un modelo de clasificaciÃ³n binaria con Spark ML utilizando Logistic Regression para predecir si una persona gana mÃ¡s de 50K al aÃ±o o no.\n",
    "\n",
    "**Dataset:** adult_income_sample.csv con 2000 registros simulados (cargado desde Google Drive)\n",
    "\n",
    "**CaracterÃ­sticas:**\n",
    "- `age`: Edad de la persona (aÃ±os)\n",
    "- `sex`: GÃ©nero (Male, Female) \n",
    "- `workclass`: Tipo de empleo (Private, Self-emp, Gov)\n",
    "- `fnlwgt`: Peso estadÃ­stico asociado al registro\n",
    "- `education`: Nivel educativo (Bachelors, HS-grad, 11th, Masters, etc.)\n",
    "- `hours_per_week`: Horas trabajadas por semana\n",
    "- `label`: Clase objetivo (>50K o <=50K)\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ **INSTRUCCIONES IMPORTANTES:**\n",
    "\n",
    "### ðŸ“‚ **Antes de ejecutar este notebook:**\n",
    "\n",
    "1. **Sube el archivo `adult_income_sample.csv` a tu Google Drive**\n",
    "2. **Ejecuta la primera celda para montar Google Drive**\n",
    "3. **Verifica que el archivo estÃ© en la ruta correcta**\n",
    "4. **Ejecuta todas las celdas secuencialmente**\n",
    "\n",
    "### ðŸ”— **Ventajas de usar Google Drive:**\n",
    "- âœ… **Control de versiones**: Mantienes el dataset original\n",
    "- âœ… **Compatibilidad**: Mismo CSV funciona en VS Code y Colab\n",
    "- âœ… **Reproducibilidad**: Resultados consistentes entre entornos\n",
    "- âœ… **ColaboraciÃ³n**: FÃ¡cil compartir datos con el equipo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b9111",
   "metadata": {},
   "source": [
    "## ðŸ”§ **1. ConfiguraciÃ³n del Entorno Google Colab**\n",
    "\n",
    "Instalamos PySpark y montamos Google Drive para acceder al dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar PySpark en Google Colab\n",
    "!pip install pyspark\n",
    "\n",
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"âœ… PySpark instalado y Google Drive montado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerÃ­as necesarias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "import os\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb318bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear sesiÃ³n de Spark optimizada para Google Colab\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IncomeClassification_Colab\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"false\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"false\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar nivel de log para reducir salida\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"âœ… SesiÃ³n Spark iniciada en Google Colab\")\n",
    "print(f\"ðŸ”¢ VersiÃ³n de Spark: {spark.version}\")\n",
    "print(f\"ðŸ“± AplicaciÃ³n: {spark.sparkContext.appName}\")\n",
    "print(f\"ðŸ–¥ï¸  Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d56a9",
   "metadata": {},
   "source": [
    "## ðŸ“‚ **2. Carga y ExploraciÃ³n de Datos desde Google Drive**\n",
    "\n",
    "Cargamos el archivo CSV desde Google Drive y exploramos la estructura de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que el archivo existe en Google Drive\n",
    "file_path = \"/content/drive/MyDrive/adult_income_sample.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"âœ… Archivo encontrado: {file_path}\")\n",
    "    print(f\"ðŸ“ TamaÃ±o del archivo: {os.path.getsize(file_path)} bytes\")\n",
    "else:\n",
    "    print(\"âŒ ARCHIVO NO ENCONTRADO!\")\n",
    "    print(\"ðŸ” Archivos disponibles en Google Drive:\")\n",
    "    !ls \"/content/drive/MyDrive/\" | head -10\n",
    "    print(\"\\nâš ï¸  Por favor, sube 'adult_income_sample.csv' a tu Google Drive\")\n",
    "    print(\"ðŸ’¡ O ajusta la ruta en la variable 'file_path'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde Google Drive\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "print(f\"âœ… Datos cargados desde Google Drive: {df.count()} registros, {len(df.columns)} columnas\")\n",
    "print(\"\\nðŸ“Š Esquema del DataFrame:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar primeros 10 registros\n",
    "print(\"ðŸ“‹ Primeros 10 registros:\")\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32537dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lisis de la distribuciÃ³n de la variable objetivo\n",
    "print(\"ðŸ“ˆ DistribuciÃ³n de la variable objetivo (label):\")\n",
    "df.groupBy(\"label\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "print(\"\\nðŸ“Š EstadÃ­sticas descriptivas de variables numÃ©ricas:\")\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206199de",
   "metadata": {},
   "source": [
    "## ðŸ”„ **3. Preprocesamiento de Variables CategÃ³ricas**\n",
    "\n",
    "Aplicamos StringIndexer y OneHotEncoder para transformar las variables categÃ³ricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variables categÃ³ricas\n",
    "categorical_cols = ['sex', 'workclass', 'education']\n",
    "\n",
    "print(\"ðŸ”„ Aplicando StringIndexer a variables categÃ³ricas...\")\n",
    "\n",
    "# StringIndexer para variables categÃ³ricas\n",
    "indexers = []\n",
    "for col_name in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_index\")\n",
    "    indexers.append(indexer)\n",
    "    print(f\"  âœ“ StringIndexer creado para: {col_name}\")\n",
    "\n",
    "# StringIndexer para la variable objetivo (label)\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "indexers.append(label_indexer)\n",
    "print(f\"  âœ“ StringIndexer creado para: label\")\n",
    "\n",
    "print(f\"\\nðŸ“ Total de StringIndexers: {len(indexers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder para variables categÃ³ricas (no para la etiqueta)\n",
    "print(\"ðŸ”„ Aplicando OneHotEncoder a variables categÃ³ricas...\")\n",
    "\n",
    "encoders = []\n",
    "for col_name in categorical_cols:\n",
    "    encoder = OneHotEncoder(inputCol=f\"{col_name}_index\", outputCol=f\"{col_name}_encoded\")\n",
    "    encoders.append(encoder)\n",
    "    print(f\"  âœ“ OneHotEncoder creado para: {col_name}\")\n",
    "\n",
    "print(f\"\\n Total de OneHotEncoders: {len(encoders)}\")\n",
    "print(\" Preprocesamiento de variables categÃ³ricas configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72b69",
   "metadata": {},
   "source": [
    "## ðŸ”§ **4. Ensamblaje de CaracterÃ­sticas**\n",
    "\n",
    "Combinamos todas las caracterÃ­sticas en un vector Ãºnico usando VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir caracterÃ­sticas para el vector final\n",
    "numeric_cols = ['age', 'fnlwgt', 'hours_per_week']\n",
    "categorical_encoded_cols = ['sex_encoded', 'workclass_encoded', 'education_encoded']\n",
    "\n",
    "# Combinar todas las caracterÃ­sticas\n",
    "feature_cols = numeric_cols + categorical_encoded_cols\n",
    "\n",
    "print(\" Configurando VectorAssembler...\")\n",
    "print(f\" CaracterÃ­sticas numÃ©ricas: {numeric_cols}\")\n",
    "print(f\" CaracterÃ­sticas categÃ³ricas codificadas: {categorical_encoded_cols}\")\n",
    "print(f\" Total de caracterÃ­sticas: {len(feature_cols)}\")\n",
    "\n",
    "# Crear VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "print(\" VectorAssembler configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc493698",
   "metadata": {},
   "source": [
    "##  **5. DefiniciÃ³n y Entrenamiento del Modelo**\n",
    "\n",
    "Configuramos el modelo de Logistic Regression y creamos el Pipeline completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295280a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar modelo de Logistic Regression\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label_index\",\n",
    "    predictionCol=\"prediction\",\n",
    "    probabilityCol=\"probability\",\n",
    "    maxIter=100,\n",
    "    regParam=0.01\n",
    ")\n",
    "\n",
    "print(\"Modelo configurado:\")\n",
    "print(f\"   Tipo: Logistic Regression\")\n",
    "print(f\"   MÃ¡ximo iteraciones: {lr.getMaxIter()}\")\n",
    "print(f\"   ParÃ¡metro regularizaciÃ³n: {lr.getRegParam()}\")\n",
    "print(\" Modelo de Logistic Regression configurado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear Pipeline con todas las etapas\n",
    "stages = indexers + encoders + [assembler, lr]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "print(\"ðŸ”§ Pipeline creado con las siguientes etapas:\")\n",
    "for i, stage in enumerate(stages):\n",
    "    print(f\"  {i+1:2d}. {type(stage).__name__}\")\n",
    "\n",
    "print(f\"\\n Total de etapas en el Pipeline: {len(stages)}\")\n",
    "print(\" Pipeline configurado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a573087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "print(\" Iniciando entrenamiento del modelo...\")\n",
    "model = pipeline.fit(df)\n",
    "print(\" Modelo entrenado exitosamente!\")\n",
    "\n",
    "# Obtener informaciÃ³n del modelo entrenado\n",
    "lr_model = model.stages[-1]  # El Ãºltimo stage es el LogisticRegression\n",
    "print(f\"\\n InformaciÃ³n del modelo entrenado:\")\n",
    "print(f\"   NÃºmero de iteraciones realizadas: {lr_model.summary.totalIterations}\")\n",
    "print(f\"   Objective History (Ãºltimos 5): {lr_model.summary.objectiveHistory[-5:]}\")\n",
    "print(\" Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fcbe2a",
   "metadata": {},
   "source": [
    "##  **6. EvaluaciÃ³n del Modelo**\n",
    "\n",
    "Evaluamos el modelo entrenado y analizamos las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones sobre el conjunto de entrenamiento\n",
    "predictions = model.transform(df)\n",
    "\n",
    "print(\" Predicciones generadas\")\n",
    "print(\" Mostrando las primeras 20 predicciones con todas las columnas relevantes:\")\n",
    "\n",
    "# Mostrar predicciones\n",
    "predictions.select(\"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\", \n",
    "                  \"label\", \"prediction\", \"probability\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e899e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con mÃ©tricas\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label_index\", rawPredictionCol=\"rawPrediction\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\" MÃ©tricas de evaluaciÃ³n:\")\n",
    "print(f\"   Ãrea bajo la curva ROC (AUC): {auc:.4f}\")\n",
    "\n",
    "# Calcular precisiÃ³n (accuracy)\n",
    "correct_predictions = predictions.filter(col(\"label_index\") == col(\"prediction\")).count()\n",
    "total_predictions = predictions.count()\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"   PrecisiÃ³n (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"   Predicciones correctas: {correct_predictions}\")\n",
    "print(f\"   Total de predicciones: {total_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8537da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusiÃ³n\n",
    "print(\" Matriz de confusiÃ³n:\")\n",
    "confusion_matrix = predictions.groupBy(\"label_index\", \"prediction\").count().orderBy(\"label_index\", \"prediction\")\n",
    "confusion_matrix.show()\n",
    "\n",
    "# DistribuciÃ³n de predicciones\n",
    "print(\"\\n DistribuciÃ³n de predicciones:\")\n",
    "predictions.groupBy(\"prediction\").count().orderBy(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e06b3",
   "metadata": {},
   "source": [
    "###  **ReflexiÃ³n sobre los Resultados**\n",
    "\n",
    "**Â¿QuÃ© observamos sobre los resultados?**\n",
    "\n",
    "1. **DistribuciÃ³n de probabilidades**: El modelo genera probabilidades entre 0 y 1 para cada predicciÃ³n, siendo mÃ¡s confiable cuando las probabilidades estÃ¡n mÃ¡s cerca de 0 o 1.\n",
    "\n",
    "2. **PrecisiÃ³n del modelo**: La precisiÃ³n (accuracy) nos indica quÃ© porcentaje de predicciones fueron correctas.\n",
    "\n",
    "3. **AUC**: El Ã¡rea bajo la curva ROC nos da una medida de quÃ© tan bien el modelo puede distinguir entre las dos clases.\n",
    "\n",
    "4. **CaracterÃ­sticas importantes**: Variables como educaciÃ³n, edad y horas trabajadas probablemente tienen mayor peso en las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591cadd",
   "metadata": {},
   "source": [
    "##  **7. PredicciÃ³n con Nuevos Datos**\n",
    "\n",
    "Creamos nuevos registros y aplicamos el modelo entrenado para hacer predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevos datos de prueba (9 registros como mÃ­nimo requerido)\n",
    "new_data = [\n",
    "    (35, \"Male\", \"Private\", 150000, \"Bachelors\", 45),      # Perfil promisorio: educaciÃ³n alta, horas normales\n",
    "    (25, \"Female\", \"Private\", 120000, \"HS-grad\", 35),      # Joven con educaciÃ³n bÃ¡sica\n",
    "    (45, \"Male\", \"Gov\", 200000, \"Masters\", 50),            # Gobierno, educaciÃ³n alta, experiencia\n",
    "    (22, \"Female\", \"Self-emp\", 80000, \"11th\", 20),         # Joven, trabajo independiente, educaciÃ³n baja\n",
    "    (55, \"Male\", \"Private\", 300000, \"Doctorate\", 60),      # Doctorado, muchas horas, experiencia\n",
    "    (30, \"Female\", \"Private\", 100000, \"Some-college\", 40), # EducaciÃ³n universitaria parcial\n",
    "    (28, \"Male\", \"Self-emp\", 90000, \"Bachelors\", 55),      # Independiente con tÃ­tulo universitario\n",
    "    (40, \"Female\", \"Gov\", 180000, \"Masters\", 42),          # Gobierno con maestrÃ­a\n",
    "    (33, \"Male\", \"Private\", 140000, \"Assoc-voc\", 38)       # EducaciÃ³n tÃ©cnica/vocacional\n",
    "]\n",
    "\n",
    "columns = [\"age\", \"sex\", \"workclass\", \"fnlwgt\", \"education\", \"hours_per_week\"]\n",
    "new_df = spark.createDataFrame(new_data, columns)\n",
    "\n",
    "print(\" Nuevos datos creados para predicciÃ³n:\")\n",
    "new_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el modelo entrenado a los nuevos datos\n",
    "print(\" Aplicando modelo entrenado a nuevos datos...\")\n",
    "new_predictions = model.transform(new_df)\n",
    "\n",
    "print(\"\\nðŸ“Š Resultados de predicciones para nuevos datos:\")\n",
    "new_predictions.select(\"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\", \n",
    "                      \"prediction\", \"probability\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6971f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretar las predicciones de manera mÃ¡s legible\n",
    "print(\"ðŸ“‹ InterpretaciÃ³n de las predicciones:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = new_predictions.select(\"age\", \"sex\", \"workclass\", \"education\", \"hours_per_week\", \"prediction\", \"probability\").collect()\n",
    "\n",
    "for i, row in enumerate(results, 1):\n",
    "    prediction_label = \">50K\" if row.prediction == 1.0 else \"<=50K\"\n",
    "    prob_high = row.probability[1]  # Probabilidad de clase >50K\n",
    "    prob_low = row.probability[0]   # Probabilidad de clase <=50K\n",
    "    \n",
    "    print(f\" Persona {i}:\")\n",
    "    print(f\"    Perfil: {row.age} aÃ±os, {row.sex}, {row.workclass}, {row.education}, {row.hours_per_week}h/semana\")\n",
    "    print(f\"    PredicciÃ³n: {prediction_label}\")\n",
    "    print(f\"    Probabilidad >50K: {prob_high:.3f} | Probabilidad <=50K: {prob_low:.3f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490f8a5",
   "metadata": {},
   "source": [
    "##  **Resumen Final del Proyecto**\n",
    "\n",
    "**Â¡ClasificaciÃ³n de Ingresos completada exitosamente para DataPros!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce46f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final del proyecto\n",
    "print(\"ðŸŽ¯ RESUMEN DEL PROYECTO - DATAPROS\")\n",
    "print(\"=\" * 60)\n",
    "print(\" Datos cargados desde Google Drive: 2000 registros\")\n",
    "print(\" Variables categÃ³ricas procesadas con StringIndexer y OneHotEncoder\")\n",
    "print(\" CaracterÃ­sticas ensambladas con VectorAssembler\")\n",
    "print(\" Modelo de Logistic Regression entrenado con Pipeline\")\n",
    "print(\" Modelo evaluado con mÃ©tricas de rendimiento\")\n",
    "print(\" Predicciones realizadas sobre 9 nuevos registros\")\n",
    "print(f\" PrecisiÃ³n del modelo: {accuracy:.1%}\")\n",
    "print(f\" AUC del modelo: {auc:.3f}\")\n",
    "print(\"\\n DataPros ahora puede predecir ingresos basado en caracterÃ­sticas demogrÃ¡ficas y laborales!\")\n",
    "print(\"\\n Ejecutado exitosamente en Google Colab con datos desde Google Drive\")\n",
    "\n",
    "# Cerrar sesiÃ³n Spark\n",
    "spark.stop()\n",
    "print(\"\\n SesiÃ³n Spark cerrada correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbdacaa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  **Evidencia de EjecuciÃ³n**\n",
    "\n",
    
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
